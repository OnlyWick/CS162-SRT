1
00:00:00,000 --> 00:00:17,440
 Welcome everyone to the second lecture. Today we are going to learn about the four fundamental

2
00:00:17,440 --> 00:00:28,900
 OS operating system concepts. And as always, please ask your questions on Q&A channel.

3
00:00:28,900 --> 00:00:35,560
 I will stop from time to time to read the questions and answer them. First, let me start

4
00:00:35,560 --> 00:00:41,600
 with some announcements. So I will have for now one office hours on Mondays between noon

5
00:00:41,600 --> 00:00:48,180
 and 1 PM. And there is more demand, I'm going to add more office hours. Of course, next

6
00:00:48,180 --> 00:00:55,440
 Monday is no office hours. Actually, that should be Monday, not Wednesday. It won't

7
00:00:55,440 --> 00:01:02,080
 be an office hour on Memorial Day. And we will add, it will be office hour will be via

8
00:01:02,080 --> 00:01:10,980
 Zoom. And I will add the link to the Zoom on the class webpage.

9
00:01:10,980 --> 00:01:19,440
 Just a reminder that the drop deadline is this Friday, early drop deadline. Please,

10
00:01:19,440 --> 00:01:27,800
 if you are thinking about dropping this class, do it right away because this will let other

11
00:01:27,800 --> 00:01:37,180
 people from the waiting list to enroll in the class. Finally, please, after the drop

12
00:01:37,180 --> 00:01:48,800
 deadline, start to sign up for the groups. Remember, we ask you to have four people in

13
00:01:48,800 --> 00:01:59,960
 a group and try that all people to attend either the same sections, this is preferable,

14
00:01:59,960 --> 00:02:08,360
 or maybe if that's not possible, if there are two sections taught by the same TA. This

15
00:02:08,360 --> 00:02:22,080
 is in order to have consistent feedback for your projects during the semester.

16
00:02:22,080 --> 00:02:41,000
 Yes, there are some, again, there are some quick questions on the chat. Please ask question

17
00:02:41,000 --> 00:02:46,600
 on the Q&A channel, not on the chat, but now one question is, are we going to have today's

18
00:02:46,600 --> 00:02:54,160
 lecture slides posted to Piazza due to website being down? Well, hopefully the website will

19
00:02:54,160 --> 00:03:01,600
 come back up, but yes, we can post them on Piazza. And a second question is when will

20
00:03:01,600 --> 00:03:10,440
 the TAI section preferences form will be released? I'm not sure any TA, head TA, Eduardo, if you

21
00:03:10,440 --> 00:03:21,360
 are here, please answer this question. If not, Alan, you ask this question, please also

22
00:03:21,360 --> 00:03:35,440
 post it on Piazza and we'll get the answer there.

23
00:03:35,440 --> 00:03:40,600
 What do I mean two section by the same TA? So what I mean here is that if not all people,

24
00:03:40,600 --> 00:03:48,600
 if there are TAs, there will be TAs or some of the TAs have two sections. So if not all

25
00:03:48,600 --> 00:03:55,040
 of you in the same group can go to the same section, pick two sections which are taught

26
00:03:55,040 --> 00:04:04,000
 by the same TA. Will the class expand to get all the people on the wait list? This class,

27
00:04:04,000 --> 00:04:11,200
 again, although it's online, it's limited because of TA resources and the staff of the

28
00:04:11,200 --> 00:04:21,200
 class doesn't actually have any kind of, you know, it's not, we do not decide who we're

29
00:04:21,200 --> 00:04:28,120
 going to get from the wait list, who is going to get enrolled in the class. This is a department

30
00:04:28,120 --> 00:04:37,720
 decision. So please ask them. We can't do much about it. When I say we, I refer to the

31
00:04:37,720 --> 00:04:43,880
 staff of the class, myself and the TAs and the leaders.

32
00:04:43,880 --> 00:04:57,120
 Okay, let's move on. So, and last thing I want to say is that please avoid private Piazza

33
00:04:57,120 --> 00:05:02,720
 posts because in many cases you are not the only one to have a question. Many other people

34
00:05:02,720 --> 00:05:09,840
 will have the same questions. Of course, if it's a personal questions, you should use

35
00:05:09,840 --> 00:05:18,320
 a private Piazza post, but otherwise please try as much as possible not to use it.

36
00:05:18,320 --> 00:05:27,720
 Okay, so let's go and start with a lecture. So what is an operating system? We discussed

37
00:05:27,720 --> 00:05:33,840
 a little bit last time during the last lecture. And this is one slide from the last lecture,

38
00:05:33,840 --> 00:05:38,560
 basically saying that, you know, the operating system is a software layer we see between

39
00:05:38,560 --> 00:05:45,920
 hardware and the applications. Okay. And it implements and provides to the application

40
00:05:45,920 --> 00:05:53,920
 a bunch of very useful functionality, provides easy, convenient abstraction to the applications.

41
00:05:53,920 --> 00:06:01,440
 So make it much easier to write the applications and using the raw hardware, protect access

42
00:06:01,440 --> 00:06:06,360
 of between the application and between the application and the operating system to the

43
00:06:06,360 --> 00:06:14,580
 shared resources, provide security and authentication and provide communication among logical entities.

44
00:06:14,580 --> 00:06:20,220
 And if you remember, you also have this slide which basically says about how you can look

45
00:06:20,220 --> 00:06:25,900
 at the operating system between, you know, based on the functionality it provides, on

46
00:06:25,900 --> 00:06:32,780
 a certain functionality it provides. So in one way, one way to look at is like a illusionist.

47
00:06:32,780 --> 00:06:42,360
 And this is when the operating system magically abstracts the hardware to the application

48
00:06:42,360 --> 00:06:53,380
 and it provides a illusion that the application use a dedicated machine with an infinite memory

49
00:06:53,380 --> 00:07:05,180
 and has access to all the files and other resources on the same dedicated machines.

50
00:07:05,180 --> 00:07:11,980
 Okay. So that's a very convenient abstraction for the users and for the application developer.

51
00:07:11,980 --> 00:07:21,160
 In reality, an application, sorry, the system, the hardware is shared between multiple applications

52
00:07:21,160 --> 00:07:29,800
 and multiple users. So therefore you need to arbitrate the access of the resources,

53
00:07:29,800 --> 00:07:36,400
 the shared resources between these applications. And this is when the operating system plays

54
00:07:36,400 --> 00:07:43,760
 a role of the referee. Okay. So it needs to provide isolation between the processes and

55
00:07:43,760 --> 00:07:51,080
 the applications. And you need to protect one process from another and the operating

56
00:07:51,080 --> 00:07:58,440
 system from processes. And finally, this application and these processes often to implement more

57
00:07:58,440 --> 00:08:03,680
 sophisticated functionality, they need to communicate with each other. They need to

58
00:08:03,680 --> 00:08:15,520
 share resources and they need to use the same services. And this, the role of the operating

59
00:08:15,520 --> 00:08:22,120
 system to provide the services, you can think about providing the glue, which keep together

60
00:08:22,120 --> 00:08:30,160
 and make this application to work together. So it provides a storage, right? Which can

61
00:08:30,160 --> 00:08:35,280
 be used by every application. It provides a window system and it provides networking,

62
00:08:35,280 --> 00:08:44,240
 which helps the applications communicate with each other. Okay. So that's pretty much where

63
00:08:44,240 --> 00:08:51,240
 we are. And next, let me just stop here to see whether there are any other questions.

64
00:08:51,240 --> 00:09:00,920
 No new questions. Yeah. Okay. So let's go a little bit through the operating system

65
00:09:00,920 --> 00:09:07,280
 history. Again, the operating system abstracting away the hardware and making the job of the

66
00:09:07,280 --> 00:09:12,560
 application developer easier, making it much easier to develop this application. This was

67
00:09:12,560 --> 00:09:20,240
 from very early on since the first computers have been developed. Okay. And there are several

68
00:09:20,240 --> 00:09:26,960
 distinct phases. The first phase, which I alluded last time, is that when hardware was

69
00:09:26,960 --> 00:09:34,040
 very expensive and humans are cheap. So this picture shows a room, you see a pretty large

70
00:09:34,040 --> 00:09:41,200
 room. Well, that's the room which hosted the entire computer, right? You need a big room,

71
00:09:41,200 --> 00:09:48,200
 almost like a warehouse room to host the entire computer, right? These are extremely expensive.

72
00:09:48,200 --> 00:09:56,400
 These fairly early computers, maybe you heard about like ENIAC in '50s, millions or tens

73
00:09:56,400 --> 00:10:06,200
 of millions of dollars in today's money. And then this was a age in which you have very

74
00:10:06,200 --> 00:10:14,960
 expensive computers and humans are relatively cheap, right? So what means that is that you

75
00:10:14,960 --> 00:10:21,760
 want to optimize, to use very efficiently the computer and you don't want to necessarily

76
00:10:21,760 --> 00:10:27,960
 to optimize the time of the humans because they are cheap, remember, right? So if they

77
00:10:27,960 --> 00:10:38,200
 need to, humans need to spend more time to optimize their programs and to make the hardware

78
00:10:38,200 --> 00:10:45,560
 usage more efficient, then so be it. It's perfectly fine. And this was again the age

79
00:10:45,560 --> 00:10:55,320
 when Thomas Watson, the founder and chairman of IBM in 1943 was saying that, "I think there

80
00:10:55,320 --> 00:11:07,360
 is a world market for maybe five computers." So, and Thomas Watson also called the world

81
00:11:07,360 --> 00:11:12,600
 market greatest salesman by the time of his death in '56.

82
00:11:12,600 --> 00:11:20,360
 Then the next big stage is in '80s, '70s and '80s, and it's the rise of the personal computer,

83
00:11:20,360 --> 00:11:34,080
 right? In mid '70s, when the first Apple was released, I think it was '76, and then you

84
00:11:34,080 --> 00:11:42,400
 have IBM PCs and compatible computers being released. And this was when hardware was becoming

85
00:11:42,400 --> 00:11:49,520
 cheaper and human more expensive. Now everyone was having access wanted to a computer and

86
00:11:49,520 --> 00:11:54,560
 you have a computer on every desk in every home. That was the vision of Bill Gates, the

87
00:11:54,560 --> 00:12:01,600
 founder of Microsoft. And finally, we are today when the hardware

88
00:12:01,600 --> 00:12:09,360
 is really cheap and humans are really expensive. And here we are talking about, you have not

89
00:12:09,360 --> 00:12:18,000
 only about your phone or tablet or your PCs, but we are talking about more and more of

90
00:12:18,000 --> 00:12:29,360
 devices around you. They have processors, your TV, your thermo type, your car, and each

91
00:12:29,360 --> 00:12:40,920
 of these platforms and devices, they do have an operating system on which you implement

92
00:12:40,920 --> 00:12:46,640
 or developers implement specialized application to control your thermostat, your TV and so

93
00:12:46,640 --> 00:13:01,520
 forth. The other thing, what happens, and we'll see that this kind of different phases

94
00:13:01,520 --> 00:13:07,640
 led to different requirements on the operating systems. The other thing is also was driven

95
00:13:07,640 --> 00:13:16,520
 and also these distinct phases is by the hardware becoming more and more plentiful, faster,

96
00:13:16,520 --> 00:13:25,200
 and faster, and cheaper, and cheaper. This led to from computers who are hosted in one

97
00:13:25,200 --> 00:13:40,040
 huge room to computers, which can be on your watch. And so this led, for instance, in the

98
00:13:40,040 --> 00:13:48,000
 early days of the big computers, the main way to use them was batch processing. And

99
00:13:48,000 --> 00:13:56,120
 what batch processing means is that you put your job in a queue. You went there to some

100
00:13:56,120 --> 00:14:02,960
 punch cards on which you write your program and you give the program to the operators

101
00:14:02,960 --> 00:14:09,400
 and you come the next day to get the results. This is what we mean is that the time of the

102
00:14:09,400 --> 00:14:15,840
 program was not that important then because it was cheap and the computer time was very

103
00:14:15,840 --> 00:14:21,680
 expensive. So you want to have very high utilization and one way to have high utilization is that

104
00:14:21,680 --> 00:14:26,640
 always you have a program to run. So you have a queue of programs which are submitted and

105
00:14:26,640 --> 00:14:30,840
 you run it one by one and then you are going to get the results when it's finished. It

106
00:14:30,840 --> 00:14:37,720
 takes hours for it to run, sometimes days. Then it's going to be multi-programming and

107
00:14:37,720 --> 00:14:44,760
 the multi-programming means now you have, they are a little bit cheaper and then you

108
00:14:44,760 --> 00:14:53,440
 want to start to use the computers in a more interactive way. And multi-programming means

109
00:14:53,440 --> 00:14:58,520
 now that instead of one program at a time, you have multiple programs running at the

110
00:14:58,520 --> 00:15:03,200
 same time. You have that one. So the time you wait for the program to finish can be

111
00:15:03,200 --> 00:15:09,400
 reduced. And then it's time sharing, which now you are using the computer in a more interactive

112
00:15:09,400 --> 00:15:16,120
 way. You have terminals which are connected to the computer. And in that case, the computer

113
00:15:16,120 --> 00:15:23,360
 wait after the human to type in, to write the program and then to execute the program.

114
00:15:23,360 --> 00:15:29,700
 And then you have obviously the personal computers where you have a computer dedicated per human.

115
00:15:29,700 --> 00:15:36,300
 And in that case, the computer now is idle 99% of the time because it's waiting for you

116
00:15:36,300 --> 00:15:44,020
 for the humans to take some action. So for the computer to respond and so forth. And

117
00:15:44,020 --> 00:15:49,440
 then ubiquitous devices are obviously the devices I mentioned for you, like your thermostat

118
00:15:49,440 --> 00:16:01,760
 and devices in your car and things like that. The operating system is a huge variety of

119
00:16:01,760 --> 00:16:07,200
 operating systems in terms of complexity. You can imagine that the operating system

120
00:16:07,200 --> 00:16:14,020
 to control on your thermostat is probably much simpler than operating system to control

121
00:16:14,020 --> 00:16:23,480
 a supercomputer. And a small OS can be just have hundreds of lines of code while larger

122
00:16:23,480 --> 00:16:30,820
 ones can have tens of millions lines of code. And they are very, very expensive to develop.

123
00:16:30,820 --> 00:16:37,600
 And because of the cost of development OS from scratch, it's very high. Actually, most

124
00:16:37,600 --> 00:16:43,960
 modern operating system have a long lineage. You can trace back the lineage long, long

125
00:16:43,960 --> 00:16:52,100
 tens of years, decades ago. So they are in linear. So therefore, the operating system

126
00:16:52,100 --> 00:16:59,560
 from today are some improved version of some very old operating systems. So this is one

127
00:16:59,560 --> 00:17:06,760
 lineage which is mostly extinct now. This was from Multics. It's one of the most, the

128
00:17:06,760 --> 00:17:17,800
 first operating system which was multitasking, multiprogrammed and time shared. And this

129
00:17:17,800 --> 00:17:25,560
 is an ancestor of Unix. And this is then you have AT&T Unix, Berkeley, BSD Unix, Altrich,

130
00:17:25,560 --> 00:17:35,840
 SunOS and BSD. Then you have actually from Mac, this is a micro channel we are going

131
00:17:35,840 --> 00:17:41,200
 to learn a little bit about it. This was developed by Carnegie Mellon University in the '90s.

132
00:17:41,200 --> 00:17:46,360
 And this is plus Unix BSD. You see it here up. So this is Berkeley Standard Distribution.

133
00:17:46,360 --> 00:17:55,280
 This is what BSD stands for. Then this source used to develop Nextstep. I'm not sure how

134
00:17:55,280 --> 00:18:05,000
 many people heard about Nextstep. This was a company that Steve Jobs founded after he

135
00:18:05,000 --> 00:18:17,600
 was pushed out from Apple the first time around. And eventually Nextstep was acquired by Apple,

136
00:18:17,600 --> 00:18:25,120
 I think in 1997. And this is how Steve Jobs came back to Apple. And then like they say,

137
00:18:25,120 --> 00:18:34,520
 there is this history. And this now is Nextstep is at the basis of Apple OS X and iPhone iOS.

138
00:18:34,520 --> 00:18:45,800
 Okay. So then is this other lineage from Linux, Linux. This was developed by Andrew Tannenbaum

139
00:18:45,800 --> 00:18:54,920
 from Rije University or Free University in Amsterdam. Again, I think in '80s. And this

140
00:18:54,920 --> 00:19:03,440
 is lineage then Linux and Android operating system and many flavor of Linux you know and

141
00:19:03,440 --> 00:19:14,400
 you use today. And then finally this lineage from, again, this is operating system developed

142
00:19:14,400 --> 00:19:22,360
 for home computers very early on. This is first on the CPM, again in '70s. And this

143
00:19:22,360 --> 00:19:30,600
 is then evolves to MS-DOS. This is Microsoft DOS. This is Microsoft first operating system.

144
00:19:30,600 --> 00:19:38,440
 And the reason for why Microsoft is a company which is today. And then Windows. So this

145
00:19:38,440 --> 00:19:46,640
 is a Microsoft lineage, Microsoft operating system lineage. Okay. So it's again, a very

146
00:19:46,640 --> 00:19:53,560
 few obviously, all the operating system you are going to work today, you can track down

147
00:19:53,560 --> 00:20:13,480
 back to probably two or three ancient operating systems. Okay. So here is a question. What

148
00:20:13,480 --> 00:20:14,520
 are examples of?

149
00:20:14,570 --> 00:20:23,070
 tasks that computers will be used for in the batch scenarios. So even today, even some

150
00:20:23,070 --> 00:20:27,430
 of the separate computers, which are again very expensive today, they are using the batch

151
00:20:27,430 --> 00:20:37,390
 mode. So for instance, today you can submit a job which perform a very expensive simulation,

152
00:20:37,390 --> 00:20:45,290
 fluid dynamics, for instance, you want to simulate airplane engine, or you can submit a batch

153
00:20:45,290 --> 00:20:50,870
 to process some huge amount of data, which will take hours. So these are some examples

154
00:20:50,870 --> 00:20:56,250
 of batch scenarios.

155
00:20:56,250 --> 00:21:11,990
 Okay. So this is another figure by basically showing how in time, some of the you have

156
00:21:11,990 --> 00:21:18,990
 on the x-axis is at time and then on the y-axis going from very large mainframes or very large

157
00:21:18,990 --> 00:21:29,950
 computers to handheld and ubiquitous devices. And you can see here also showing you different

158
00:21:29,950 --> 00:21:36,590
 functionality provided by the operating systems and the progression of the operating system

159
00:21:36,590 --> 00:21:42,030
 here from Multics to Unix.

160
00:21:42,030 --> 00:21:51,030
 Okay. So the main thing we are going to learn in this lecture is these four fundamental

161
00:21:51,030 --> 00:21:57,870
 operating system concepts. And we alluded to them in the last lecture, but now we are

162
00:21:57,870 --> 00:22:08,430
 going to go in more depth. The first one is Thread. This provides you execution context.

163
00:22:08,430 --> 00:22:13,710
 It fully describes the program state, which means it's all the state which is needed to

164
00:22:13,710 --> 00:22:29,430
 run the program. Then is Address Space. The address space is the program, the set of addresses,

165
00:22:29,430 --> 00:22:36,950
 memory addresses within which the program executes. The code of the program has to be

166
00:22:36,950 --> 00:22:41,910
 stored in memory. The data of the program is going to be stored in memory. The output

167
00:22:41,910 --> 00:22:44,870
 has to be stored in memory.

168
00:22:44,870 --> 00:22:55,630
 Then is a Process. So a process is basically consisting of this address space and a thread,

169
00:22:55,630 --> 00:23:03,430
 right? So it consists of all the resources which are required by a program and all the

170
00:23:03,430 --> 00:23:09,590
 state which is required by the program to run.

171
00:23:09,590 --> 00:23:17,870
 And finally, the Dual Mode Operation and Protection. And this is refers about how is your operating

172
00:23:17,870 --> 00:23:24,750
 system co-exist on the same hardware with the processes and how is your operating system

173
00:23:24,750 --> 00:23:31,470
 protecting, protective from the processes, right? Because the user processes, if there

174
00:23:31,470 --> 00:23:36,550
 is no such protection, it can change the state of the operating system. The operating system

175
00:23:36,550 --> 00:23:43,990
 can crash. So everything halts, right? So how you are going to avoid that?

176
00:23:43,990 --> 00:23:51,990
 So let's look a little bit about all the journey from writing the program to executing the

177
00:23:51,990 --> 00:24:00,190
 program. So as you know, you are writing the program, which is you already wrote many programs

178
00:24:00,190 --> 00:24:06,910
 by now. So you edit the program using your editor, Emacs or your favorite editor or PyCharm

179
00:24:06,910 --> 00:24:15,550
 or Visual Code or things like that. Then you compile the code and as the code is interpreted

180
00:24:15,550 --> 00:24:23,710
 like Python. But if you have C code, as you know, you compile it and you get an executable,

181
00:24:23,710 --> 00:24:31,630
 which is a code. Executable contains a code which can be interpreted and it can be around

182
00:24:31,630 --> 00:24:38,670
 by the processors. The processors understands, right? And now this executable is loaded in

183
00:24:38,670 --> 00:24:48,350
 the memory of the computer and then it's executed. But when it's loaded in memory, there are

184
00:24:48,350 --> 00:24:54,310
 several segments of the memory or several partitions of the memory where different kinds

185
00:24:54,310 --> 00:25:09,110
 of data is stored. One part is where you keep the partitions. One partition is where you

186
00:25:09,110 --> 00:25:18,710
 keep the code, the instructions of the program. Then you have where you keep the data and

187
00:25:18,710 --> 00:25:29,590
 the data you statically defined. For instance, you say, and when you create an array or variables,

188
00:25:29,590 --> 00:25:37,950
 and you see static. Then hip is where you define and you create dynamic data structures.

189
00:25:37,950 --> 00:25:43,670
 Like for instance, this is when you allocate memory. When you allocate memory, this happens

190
00:25:43,670 --> 00:25:51,750
 as a runtime after the program starts executed. And therefore, the heap is going to change

191
00:25:51,750 --> 00:25:57,470
 during the runtime, depending on how much dynamic memory you are allocating for your

192
00:25:57,470 --> 00:26:06,150
 dynamic data structures. Finally, you have a stack. The stack is used and it's used for

193
00:26:06,150 --> 00:26:15,510
 instance, to store the variables you are going to declare within a function. And it's also

194
00:26:15,510 --> 00:26:21,990
 used to store the return address when you call a function. After the function is done,

195
00:26:21,990 --> 00:26:28,070
 you need to know where you go back in the program. Again, we'll discuss a lot more about

196
00:26:28,070 --> 00:26:36,990
 each of these different types of data and memory. And finally here you have the operating

197
00:26:36,990 --> 00:26:56,710
 system memory. So that's pretty much it. Let me stop and see. Okay. No new questions. Please

198
00:26:56,710 --> 00:27:10,790
 again, keep the question coming. Great. So how do you execute the program? If you remember,

199
00:27:10,790 --> 00:27:18,590
 and this is from 61c, if you remember, you basically have a bunch of instructions which

200
00:27:18,590 --> 00:27:25,030
 are in memory, and then you have a program counter called SoPC, which point out to the

201
00:27:25,030 --> 00:27:36,390
 current instruction being executed from memory. So what happens when you take the instruction,

202
00:27:36,390 --> 00:27:43,550
 you fetch the instruction, which is pointed to by the program counter, and then this instruction

203
00:27:43,550 --> 00:27:51,750
 is decoded and then it's executed. And this is basically down here, you see the processor,

204
00:27:51,750 --> 00:28:03,830
 like a core. And a core typically consists from an Alu arithmetic logic unit, which performs

205
00:28:03,830 --> 00:28:09,150
 the operation addition, subtraction, and things like that. And a bunch of registers, what

206
00:28:09,150 --> 00:28:15,070
 are the arguments of these operations in many cases. And registers are very fast to address

207
00:28:15,070 --> 00:28:24,590
 because they are very, very low latency. And then after you execute an instruction, the

208
00:28:24,590 --> 00:28:34,390
 program counter is incremented and you are going to the next instruction. So very simple.

209
00:28:34,390 --> 00:28:40,550
 So this is another view here about on the right hand side, you are going to have the

210
00:28:40,550 --> 00:28:48,630
 memory with a bunch of instructions and a bunch of data. And on the left hand side,

211
00:28:48,630 --> 00:28:57,030
 you have what is a processor, which is fetching the instruction and execute the instruction.

212
00:28:57,030 --> 00:29:04,830
 And there you have on the left hand side, a bunch of registers R0 to R31. And you have

213
00:29:04,830 --> 00:29:10,310
 another set of register from F0 to F30. The difference typically between the set of register

214
00:29:10,310 --> 00:29:19,230
 because the second set of register is for floating point operations. The R0 to R31 typically

215
00:29:19,230 --> 00:29:25,270
 are for fixed point operations. And then you have the program counter. So it's again, you

216
00:29:25,270 --> 00:29:30,310
 fetch the instruction as a program counter, you decode it, you execute it possibly using

217
00:29:30,310 --> 00:29:35,510
 the registers. Some of the argument of the instruction can be addressed in memory and

218
00:29:35,510 --> 00:29:41,350
 write the results to the registers or memory. And then you go to the next instruction. Okay.

219
00:29:41,350 --> 00:29:57,990
 And repeat. Okay. So let me see the questions. The question is there one program counter

220
00:29:57,990 --> 00:30:06,190
 per thread. The program counter is typically a register in the processor. So it's typically

221
00:30:06,190 --> 00:30:10,270
 only one program counter. It's maybe two if you have a user program counter, but it's

222
00:30:10,270 --> 00:30:15,390
 one. What happens, and we are going to see later in this lecture that when you are going

223
00:30:15,390 --> 00:30:20,670
 to do context switching, what is called when you go to another to start executing a thread,

224
00:30:20,670 --> 00:30:26,830
 the first action you do, you take is to load the program counter, which is say somewhere

225
00:30:26,830 --> 00:30:33,030
 in memory, the current program counter of the thread corresponding to the thread into

226
00:30:33,030 --> 00:30:40,270
 the processor program counter. Right. So, but the program counter from the processor

227
00:30:40,270 --> 00:31:00,550
 point of view, it's only one, it's not per thread. So, okay. Let me just. So the thread

228
00:31:00,550 --> 00:31:07,110
 of control, again, this contains a state required to run the program. Right. So what does it

229
00:31:07,110 --> 00:31:21,750
 mean? It's basically, it contains, sorry. It contains a program counter and then it contains

230
00:31:21,750 --> 00:31:29,230
 also pointers to where all these other kinds of regions in memory start. Like for instance,

231
00:31:29,230 --> 00:31:36,190
 it contains the, for the stack pointer, the stack pointer, it's basically where is a stack

232
00:31:36,190 --> 00:31:42,510
 starts from. It contains a heap pointer, it's an address from the where the heap starts

233
00:31:42,510 --> 00:31:54,870
 growing. And so, and it contains also what it's in registers, right? Because the state

234
00:31:54,870 --> 00:32:02,430
 in the registers is used by the instructions. And a thread is executing, like I mentioned

235
00:32:02,430 --> 00:32:09,910
 earlier, when it's resident on the processor, when the state is, the thread state is loaded

236
00:32:09,910 --> 00:32:18,150
 in the processor. PC Regis program counter holds the address of the executing instruction

237
00:32:18,150 --> 00:32:24,030
 in the thread and again, register holds some of the root state of the thread. It's called

238
00:32:24,030 --> 00:32:32,990
 the root state. Okay. So that's kind of what the thread is about. So all the state which

239
00:32:32,990 --> 00:32:43,310
 is needed to execute that program. Program counter, state of the registers, heap pointer,

240
00:32:43,310 --> 00:32:56,510
 stack pointers, and a few others. Now the address space is basically the memory addresses

241
00:32:56,510 --> 00:33:11,990
 or the memory regions where the data and the code of the programs are stored. Okay. The

242
00:33:11,990 --> 00:33:22,190
 addresses are typically it's the size of the memory addressable memory, which is very important

243
00:33:22,190 --> 00:33:28,230
 of the size of the memory. The size of the addressable memory is given by the number

244
00:33:28,230 --> 00:33:35,670
 of bits of the processor typically. So if you have a 30 bits processor, there are two

245
00:33:35,670 --> 00:33:47,870
 power 32 or 4 billion addresses, which means four megabytes of memory. If it's byte addressable,

246
00:33:47,870 --> 00:33:53,110
 if it's 64 bits, it's two power 64, which is a huge amount of memory. Okay. This is

247
00:33:53,110 --> 00:33:58,030
 addressable memory. Like we are going to see, this is different from the physical memory.

248
00:33:58,030 --> 00:34:05,550
 The physical memory can be smaller and typically smaller than the addressable memory. But then

249
00:34:05,550 --> 00:34:11,030
 you are going to have a process you are going to learn in school of virtualization and address

250
00:34:11,030 --> 00:34:16,750
 translation. We are going to even talk about this lecture, which is going to create you

251
00:34:16,750 --> 00:34:22,070
 the image and the illusion that you have access to the entire addressable memory in a smaller

252
00:34:22,070 --> 00:34:34,110
 physical memory. Okay. And of course, what happens when you read or write to an address,

253
00:34:34,110 --> 00:34:43,870
 maybe nothing or you act like a regular memory. A regular memory means that you read the value

254
00:34:43,870 --> 00:34:49,990
 from that memory and you write the value to that memory. Perhaps you can ignore writes.

255
00:34:49,990 --> 00:34:59,990
 For instance, if your process is writing to an address which doesn't belong to that process,

256
00:34:59,990 --> 00:35:08,030
 then maybe it's going to be ignored. Or maybe it causes IO operations. So as you'll see,

257
00:35:08,030 --> 00:35:18,190
 there are memory mapped input output designs and architectures in which, for instance,

258
00:35:18,190 --> 00:35:22,510
 if you want to communicate to a device like a keyboard, you want to read from a keyboard

259
00:35:22,510 --> 00:35:29,670
 or you want to communicate to the printer, there are certain predefined memory addresses

260
00:35:29,670 --> 00:35:34,470
 where you have to write. For instance, it's a predefined memory address you read from

261
00:35:34,470 --> 00:35:40,390
 and that's what you are going to get the input from the keyboard. There is another predefined

262
00:35:40,390 --> 00:35:46,870
 memory address or a range of addresses where you can write and that data is going to the

263
00:35:46,870 --> 00:35:55,790
 printer. Or perhaps it causes an exception, like an example I gave to you earlier on when

264
00:35:55,790 --> 00:36:02,590
 you are going to write to a data to an address which doesn't belong to you or say to the

265
00:36:02,590 --> 00:36:09,230
 address owned by the operating system. It can be ignored, but in many cases you get

266
00:36:09,230 --> 00:36:15,850
 a segmentation fault. You cannot cause an exception. And one exception, the offending

267
00:36:15,850 --> 00:36:28,910
 program is going to basically stop, crash. So again, you have a bunch of region or segment.

268
00:36:28,910 --> 00:36:36,430
 You have the code segment. The code segment I already mentioned to you contains the instruction

269
00:36:36,430 --> 00:36:45,410
 of the program. You have the stack segment. I told you how, again, earlier what it contains,

270
00:36:45,410 --> 00:36:51,270
 it can contains the variable you are going to declare within a function and also the

271
00:36:51,270 --> 00:37:00,870
 return addresses from a function. And the stack grows from high to low. So grows, so

272
00:37:00,870 --> 00:37:07,770
 to speak, downwards. And because you add, when you call a function, you add things on

273
00:37:07,770 --> 00:37:15,150
 the stack. And then you have the heap, which is for dynamic data. When you allocate data

274
00:37:15,150 --> 00:37:24,250
 during the program execution and you're growing from low level of low addresses to high addresses.

275
00:37:24,250 --> 00:37:34,690
 So let's see, there are some questions here. Where does the OS save all the state and the

276
00:37:34,690 --> 00:37:43,830
 registered values when changing a task? So it's a threat control block PCB. This is where

277
00:37:43,830 --> 00:37:54,450
 it says it stores. So you have a data structure which associated on each thread and which

278
00:37:54,450 --> 00:38:03,590
 is managed by the operating system. And in that block or region, you save all the state

279
00:38:03,590 --> 00:38:09,310
 associated with the thread. So when we say that the process has a virtual address space

280
00:38:09,310 --> 00:38:18,230
 zero to FF, it doesn't imply that it has free reign to write to those services. Absolutely.

281
00:38:18,230 --> 00:38:24,130
 Well let me, sorry. Let me, there are two views of the memory. And again, this is very

282
00:38:24,130 --> 00:38:32,170
 important to, and this is about virtualization. It's about creating the illusion. It's a memory,

283
00:38:32,170 --> 00:38:38,410
 it's a physical memory and the physical memory is partitioned between different processes.

284
00:38:38,410 --> 00:38:46,790
 Okay. Now there is also what the illusion actually of the process, the illusion of the

285
00:38:46,790 --> 00:38:53,850
 process is that it has an address from zero, zero to FF. It has an entire address space.

286
00:38:53,850 --> 00:39:07,450
 And the application in principle can write at any of these addresses. Okay. And, but

287
00:39:07,450 --> 00:39:15,390
 typically the operating system takes care for, so that the application does a shooting

288
00:39:15,390 --> 00:39:21,890
 its foot, right? For instance, you cannot write on the stack because if you can't write

289
00:39:21,890 --> 00:39:29,430
 on the stack, the program will crash, right? So the operating system will impose some restrictions.

290
00:39:29,430 --> 00:39:34,750
 So you don't have a free reign. You do see the entire address space. Again, you don't

291
00:39:34,750 --> 00:39:41,310
 have free reign, but I just want to, and to plant the seed now, and we are going to do

292
00:39:41,310 --> 00:39:46,190
 this, to say this over and over, because there are two views of the memory. You have physical

293
00:39:46,190 --> 00:39:52,110
 memory, which is partitioned between different applications. You have data code from different

294
00:39:52,110 --> 00:39:57,330
 applications residing in the physical memory at the same time. And then you have the virtual

295
00:39:57,330 --> 00:40:04,210
 memory, which is basically what is presented to the application. And there you create the

296
00:40:04,210 --> 00:40:09,190
 illusion that each application, each process has access to the full address space with

297
00:40:09,190 --> 00:40:23,670
 some constraints, like I explained. Okay. So, okay. So, so here is exactly what I mentioned

298
00:40:23,670 --> 00:40:27,990
 earlier about the physical memory. So you see on the right hand side, you have the physical

299
00:40:27,990 --> 00:40:28,990
 memory.

300
00:40:29,140 --> 00:40:34,900
 memory, as you can see, you have, and on the left hand side, you have the operating system

301
00:40:34,900 --> 00:40:42,580
 with N processes, green, yellow, orange. So now in the physical memory, you can see that you have

302
00:40:42,580 --> 00:40:52,180
 instructions, the code and data from different processes. And they are all residing in the same

303
00:40:52,180 --> 00:40:59,300
 physical memory. And each of these processing is only going to see only its own data. They

304
00:40:59,300 --> 00:41:09,380
 shouldn't see the other process data. So now what is the multi-programming about? Multi-programming

305
00:41:09,380 --> 00:41:15,620
 about is about having different processes, like I said earlier, earlier I said about jobs, but

306
00:41:15,620 --> 00:41:22,100
 the process is the same thing. You have different processes running and running at the same time.

307
00:41:22,580 --> 00:41:28,900
 On the same, on a single machine. And now how do you give the illusion? Because the operating

308
00:41:28,900 --> 00:41:33,860
 system provides the illusion that despite you have different processes running at the same time,

309
00:41:33,860 --> 00:41:44,020
 on the same hardware, each process believes that it is allowed. And the only way you can give that,

310
00:41:44,020 --> 00:41:48,900
 you have to share, you have to multiplex the resources. And there are multiple resources. One

311
00:41:48,900 --> 00:41:57,540
 is the CPU. And if you have a single processor, how do you provide illusion of having multiple

312
00:41:57,540 --> 00:42:04,260
 processors, one for each processor? Well, as we discussed last time, you split the processors in

313
00:42:04,260 --> 00:42:11,300
 time quanta or time slices. And we give a time quanta or a time slice to a different process.

314
00:42:12,660 --> 00:42:19,540
 So say it's 10 milliseconds, the time slice is 10 milliseconds, for 10 milliseconds you run process

315
00:42:19,540 --> 00:42:25,300
 one, then we switch for the next 10 milliseconds to process two, for the next 10 milliseconds to

316
00:42:25,300 --> 00:42:30,500
 process three, and then come back to process one. This is one way to do it. So you multiplex it in

317
00:42:30,500 --> 00:42:40,660
 time. And each, this kind of virtual CPU needs to hold this program counter, stack pointer,

318
00:42:40,660 --> 00:42:44,820
 registers, and things like that. So this is a state which is associated with the thread.

319
00:42:44,820 --> 00:42:50,660
 And because when you run something on this virtual CPUs, it's a thread.

320
00:42:50,660 --> 00:42:57,620
 And obviously the question now is about how you switch from a virtual CPU to the next one.

321
00:42:57,620 --> 00:43:05,620
 This is what you do. You save the state of the virtual CPUs and here running the state of the

322
00:43:05,620 --> 00:43:12,980
 virtual CPU is the same as a state of the thread running on that virtual CPU, in that time slice.

323
00:43:12,980 --> 00:43:17,780
 And you load the state for the next virtual CPU or the next thread you are going to execute.

324
00:43:17,780 --> 00:43:27,540
 And then you execute, you run the next thread. So it's again, just only to make sure here,

325
00:43:27,540 --> 00:43:33,300
 since I'm not confusing, you have only one CPU and in this particular case, and you want to

326
00:43:33,300 --> 00:43:42,820
 multiplex it. So you are going to multiplex it in time. And therefore each process is provided with

327
00:43:42,820 --> 00:43:50,820
 the illusion that it owns a processor albeit a slower processor. And by virtual CPU here, we mean

328
00:43:50,820 --> 00:44:02,740
 that time partition part of the CPU, which is kind of owned by a particular process.

329
00:44:03,540 --> 00:44:11,620
 Right? And when you, from the process, when you have each process, if you remember has a thread

330
00:44:11,620 --> 00:44:22,900
 and will again repeat that soon. And that thread is a part which is running on the processor

331
00:44:22,900 --> 00:44:34,420
 or the virtual CPU. Okay. Let me, you said a program can write on the stack, but when you

332
00:44:34,420 --> 00:44:49,300
 write assembly, we often move the stack pointer and write. Yes, that's true. So basically you

333
00:44:49,300 --> 00:44:53,380
 said a program can write on the stack, but when you write assembly, you often move the stack

334
00:44:53,380 --> 00:45:02,260
 pointer and drive to the stack and you are a bit confused. So when you write an assembly,

335
00:45:02,260 --> 00:45:08,820
 you don't go through the compiler. So you don't have anyone to put any kind of constraints of what

336
00:45:08,820 --> 00:45:17,620
 you are going to do. So you can indeed do almost everything. You also need to, so you need to do

337
00:45:17,620 --> 00:45:24,500
 that. But when you write a typical program, like in high-level languages, you compile it and the

338
00:45:24,500 --> 00:45:30,500
 compiler is going to put additional constraints about what you can do. Who's the program knows

339
00:45:30,500 --> 00:45:40,500
 that the CPU is time-partitioned? No. In general, no. What is exactly slower when in reality it is

340
00:45:40,500 --> 00:45:47,860
 multiplex? What I mean slower is, when I mean slower, I mean, imagine that you have a CPU

341
00:45:47,860 --> 00:46:01,220
 and it's, and if the CPU is partitioned between two processes, then each process and each process

342
00:46:01,220 --> 00:46:07,620
 will alternatively use a 10 millisecond, run for 10 milliseconds. This means that each process will

343
00:46:07,620 --> 00:46:17,700
 see a processor, which is half the speed of the original processor. Right? Because for instance,

344
00:46:17,700 --> 00:46:28,020
 out of one second, each process will use a CPU only for 500 milliseconds. Okay? So it's

345
00:46:29,220 --> 00:46:41,940
 half slow, as slow as the real CPU. What is done differently for context switching between

346
00:46:41,940 --> 00:46:49,140
 strength of the same process versus different processes? Oh, this again, this is probably too

347
00:46:49,140 --> 00:47:00,020
 early. We'll learn a lot, but you know. So in short, the answer here is that

348
00:47:00,020 --> 00:47:07,380
 when you change, when you switch, do context switching between the thread, you only need to

349
00:47:07,380 --> 00:47:15,860
 switch, context switch is a state of the thread, which is a bunch of registers and pointers.

350
00:47:15,860 --> 00:47:25,060
 It's very light. When you are going to switch between different processes, you need also to

351
00:47:25,060 --> 00:47:32,500
 switch the state about all the resources. For instance, memories, there is a memory table

352
00:47:32,500 --> 00:47:37,300
 to ensure the translation between these virtual address space and physical address space.

353
00:47:39,380 --> 00:47:47,140
 There is a file descriptors. So it's a lot of more state you need to switch when you switch

354
00:47:47,140 --> 00:48:01,540
 between processes. Where are the state blocks stored? So, the thread control blocks or all

355
00:48:01,540 --> 00:48:08,260
 the state is stored, is stored in the operating system, by the operating system and managed by

356
00:48:08,260 --> 00:48:14,020
 the operating system. Isn't there overhead with switching from one virtual CPU to another?

357
00:48:14,020 --> 00:48:23,300
 Yes, absolutely. There is an overhead when switching from one virtual CPUs to another,

358
00:48:23,300 --> 00:48:33,540
 because we need to save in those states like the person who asked the question correctly

359
00:48:34,420 --> 00:48:41,540
 identified. Is it just necessary inefficiency we accept in order to multiplex? Yes, it is.

360
00:48:41,540 --> 00:48:46,180
 How about those programs that are time sensitive? Well,

361
00:48:46,180 --> 00:48:58,580
 when the programs are time sensitive, typically you may have an operating system which has real

362
00:48:58,580 --> 00:49:07,540
 time support. In these operating systems, you can specify by when a particular task should be

363
00:49:07,540 --> 00:49:14,660
 executed and they are going to ensure that that task will be executed by that time. Or you can,

364
00:49:14,660 --> 00:49:22,900
 other ways you can specify in the operating system will guarantee that you are going to get a minimum

365
00:49:22,900 --> 00:49:34,660
 share of the CPU. So, if you get a minimum share of the CPU, then presumably you are guaranteed

366
00:49:34,660 --> 00:49:40,980
 that you can finish some of the operations or your operations in time.

367
00:49:46,020 --> 00:49:54,340
 For instance, this is a continuation. This is a question from Yufeng. For example, some programs

368
00:49:54,340 --> 00:49:59,300
 receive data from network. Wouldn't context switching the program during the transmission

369
00:49:59,300 --> 00:50:10,900
 cause trouble? No, well, it's the other way around. Actually, when you get something from

370
00:50:10,900 --> 00:50:17,940
 the network, there is an interrupt and you are going to interrupt the processes, which are

371
00:50:17,940 --> 00:50:23,700
 actually application processes, which are actually running. And then after you do the work, you get

372
00:50:23,700 --> 00:50:29,620
 the data, you return from the interrupt and you are going to continue the processes. Typically,

373
00:50:29,620 --> 00:50:36,340
 so it's a little bit the other way around. It's not like a process interrupt the transmission

374
00:50:37,220 --> 00:50:42,980
 or receiving data. Where is the current start block information being stored for each virtual

375
00:50:42,980 --> 00:50:48,980
 CPU? Like I mentioned, this is in the operating system. Following up on the assembly, giving you

376
00:50:48,980 --> 00:50:55,380
 free-running questions, are segmentation faults a C-Sync or will you also be prohibitive on the

377
00:50:56,900 --> 00:51:08,020
 assembly level? Yeah, the segmentation faults are the C-Sync. It's like an assembly level

378
00:51:08,020 --> 00:51:16,820
 because it gives you a lot of more flexibility. We see you can write all over the place. But again,

379
00:51:16,820 --> 00:51:22,500
 when you have, like for instance, if you run Java or things like that, you cannot do it.

380
00:51:23,460 --> 00:51:31,300
 And this is enforced by your compilers. It can be type, if you probably heard about being type

381
00:51:31,300 --> 00:51:37,940
 safety, type safe. So then they verify that actually when you write the program, you cannot,

382
00:51:37,940 --> 00:51:43,780
 for instance, overwrite on the stack, write on the stack. So in short answer, assembly language,

383
00:51:43,780 --> 00:51:49,940
 C language, you can do it. Higher level languages, you cannot do it. The compilers will take care of

384
00:51:49,940 --> 00:51:59,700
 that. What is the state block? Maybe if I say state block, this is not the correct term,

385
00:51:59,700 --> 00:52:06,660
 it's a thread control block and this process control block. And this is again, the state

386
00:52:06,660 --> 00:52:13,380
 control block contains all the state which is associated with a particular thread, program

387
00:52:13,380 --> 00:52:21,540
 counters, stack pointer and registers. What was the difference between a thread

388
00:52:21,540 --> 00:52:28,740
 control block and process control block? Well, like I mentioned, the process control block

389
00:52:28,740 --> 00:52:35,220
 has all the state associated with the resources associated with that process.

390
00:52:37,700 --> 00:52:43,940
 Like file descriptors and base translation information and things like that.

391
00:52:43,940 --> 00:52:50,100
 Okay, let's move on. But thanks for the question, this is great.

392
00:52:50,100 --> 00:52:58,420
 And if I don't answer a particular question, you can repeat it. Feel free.

393
00:53:00,020 --> 00:53:10,820
 Okay, so let me see. Now, when you have multiple processes running on the same hardware,

394
00:53:10,820 --> 00:53:17,140
 you need to multiply the hardware and the basic problem is what is called this concurrency.

395
00:53:17,140 --> 00:53:25,300
 And concurrency meaning, again, multiple processes wanting to access the same hardware.

396
00:53:25,860 --> 00:53:38,180
 Okay. And because you want to multiplex single CPU, memory, IO devices and things like that.

397
00:53:38,180 --> 00:53:48,180
 And remember, again, the role of the operating system at the same time is to provide the illusion

398
00:53:49,540 --> 00:53:58,500
 that each of these processes own a single machine. It's the only one executing on the machine.

399
00:53:58,500 --> 00:54:05,460
 So the operating system is in charge to arbitrate, to coordinate, to manage all these concurrent

400
00:54:05,460 --> 00:54:16,180
 activities while providing this single machine abstraction to the processes. Okay. So that's

401
00:54:16,180 --> 00:54:26,420
 kind of hard. So one of the main abstraction and okay, so one of the main resources needs to be

402
00:54:26,420 --> 00:54:36,180
 multiplexed is a memory, is a physical memory. And the way this is done, it's using the concepts of

403
00:54:36,180 --> 00:54:45,780
 virtual memory and we can extend that concept to the machine, right, to the entire machine.

404
00:54:46,340 --> 00:54:53,540
 So what we call when I said that we provide the illusion to a process that it owns

405
00:54:53,540 --> 00:54:58,580
 is dedicated machine, that machine is called virtual machine,

406
00:54:58,580 --> 00:55:02,740
 or we also refer to it as a virtual machine. Okay.

407
00:55:02,740 --> 00:55:11,060
 And then the question then it's about how to multiplex these virtual machines.

408
00:55:11,060 --> 00:55:16,500
 And the virtual machine has these virtual CPUs, virtual memory, and so forth.

409
00:55:16,500 --> 00:55:27,220
 The first system doing this was the system, short and interesting name,

410
00:55:27,220 --> 00:55:36,980
 and really was a few thousand lines of code. The OS 360, which arguably was one of the first and

411
00:55:36,980 --> 00:55:48,100
 probably the first successful commercial operating system created by IBM was having at that time,

412
00:55:48,100 --> 00:55:54,500
 1 million lines of code, which was huge. Today, probably you have Windows has tens of millions

413
00:55:54,500 --> 00:56:01,700
 lines of code or even more. And it's again, this just show you another data point about

414
00:56:01,700 --> 00:56:13,220
 how complex this operating system grew over time. And this is a funny thing, right? It's like

415
00:56:13,220 --> 00:56:20,580
 probably the number of bugs in OS 360 were probably the same or larger than the number

416
00:56:20,580 --> 00:56:40,900
 of lines of code in the system. Okay. So, now what are some of the consequences of sharing?

417
00:56:40,900 --> 00:56:49,140
 If you have only threads, the threads are going to share the same address space.

418
00:56:49,780 --> 00:56:59,060
 Okay. Which means that the threads can have access to the other threads data, for instance.

419
00:56:59,060 --> 00:57:05,140
 So they can share, but this means that they can also change the data of a different thread.

420
00:57:05,140 --> 00:57:17,460
 So that's very important to keep in mind. And here is a question, can a thread overwrite

421
00:57:17,460 --> 00:57:24,580
 operating system functions? We are not in the class to ask the class and people to answer,

422
00:57:24,580 --> 00:57:34,100
 but the answer here is no, because the operating system doesn't run in the same address space.

423
00:57:34,100 --> 00:57:41,780
 Okay. But it's again, all the threads in the same address space, they can see each other beta,

424
00:57:41,780 --> 00:57:49,220
 they can read each other data, they can write each other data. Okay. And actually there are

425
00:57:49,220 --> 00:57:59,460
 systems in the past which have this mode like Windows 3.1, which was the first really successful

426
00:57:59,460 --> 00:58:07,860
 Windows operating system from Microsoft and the early Macintosh operating systems. This is before

427
00:58:07,860 --> 00:58:19,220
 OS X, in which you have this kind of threads are in the same address space. Even more,

428
00:58:19,220 --> 00:58:34,020
 the operating system didn't actively share the CPU among the applications. Okay. Instead,

429
00:58:34,020 --> 00:58:40,740
 the application have to use this kind of common yield to relinquish the CPU so other

430
00:58:40,740 --> 00:58:49,700
 application can wrap. Right. So misbehaving application who never use yield can monopolize

431
00:58:49,700 --> 00:59:01,860
 the entire system and hang every other application. Okay. So this kind of... And so therefore,

432
00:59:01,860 --> 00:59:11,620
 what we want though, we want to have protection. Right. We want that we have two processes and this

433
00:59:11,620 --> 00:59:17,860
 is a concept of process is kind of encapsulate the protection because the thread in each process

434
00:59:17,860 --> 00:59:23,140
 can see each other data, can modify each other data, but threads from different processes cannot

435
00:59:23,140 --> 00:59:31,460
 have access to the data from the other process. Okay. Because the process contains the address

436
00:59:31,460 --> 00:59:40,580
 space and the address space, it's a unit of protection of the address space in the memory.

437
00:59:40,580 --> 00:59:48,980
 And here it's... So here again, you have two programs of two processes, the brown one and

438
00:59:48,980 --> 00:59:54,580
 the green one, process one and process two, and here process two shouldn't have access to the

439
00:59:54,580 --> 01:00:00,580
 memory of process one, shouldn't have access to the operating system memory or shouldn't have

440
01:00:00,580 --> 01:00:11,860
 access to the file descriptors of other processes. Okay. Typically, when they try to access

441
01:00:11,860 --> 01:00:19,620
 resources, they don't own a process to operating system will cause a segmentation fault and will

442
01:00:19,620 --> 01:00:31,300
 crash this offending process. Okay. Let me just... There are a few more questions.

443
01:00:31,300 --> 01:00:38,660
 How are operating system tested in development when the complexity is very high?

444
01:00:38,660 --> 01:00:43,540
 Well, that's why there are so few operating system being developed or new...

445
01:00:43,710 --> 01:00:47,990
 operating system because it's fundamentally extremely hard.

446
01:00:47,990 --> 01:00:56,830
 You know, it's just, you know, good software engineering practices.

447
01:00:56,830 --> 01:01:03,030
 You are very aggressive during unit testing, end-to-end testing and so forth.

448
01:01:03,030 --> 01:01:09,430
 And even so, with all of these, because they are so complex, many operating systems still

449
01:01:09,430 --> 01:01:11,310
 have bugs.

450
01:01:11,310 --> 01:01:19,150
 And I'm not sure I have that plot, but it was a plot in which you can see like, you

451
01:01:19,150 --> 01:01:25,590
 know, when people debug the operating system, initially you are going to have a lot of bugs.

452
01:01:25,590 --> 01:01:32,310
 And then after a while, the rate at which new bugs occur, it's reducing.

453
01:01:32,310 --> 01:01:35,910
 And it's kind of when that rate flattens, then you shield the operating system.

454
01:01:35,910 --> 01:01:38,030
 This doesn't mean that you have zero bugs.

455
01:01:38,030 --> 01:01:41,870
 It just seems that the number of bugs, it's rare enough.

456
01:01:41,870 --> 01:01:45,510
 So the operating system is usable.

457
01:01:45,510 --> 01:01:53,230
 Yeah, all the CPU's share the same resources.

458
01:01:53,230 --> 01:02:00,470
 Is this, yeah, I was saying, probably I misspoke there by saying the question is by saying

459
01:02:00,470 --> 01:02:06,230
 the all CPU share the same resources, is it referring to stress within a single process

460
01:02:06,230 --> 01:02:10,710
 or process sharing resources and so forth.

461
01:02:10,710 --> 01:02:17,510
 And I was referring at basically all threads in the same process share the same resources.

462
01:02:17,510 --> 01:02:24,390
 Then all processes also share the same physical resources in terms of the CPU and in terms

463
01:02:24,390 --> 01:02:30,350
 of physical memory.

464
01:02:30,350 --> 01:02:32,070
 How are address spaces allowed?

465
01:02:32,070 --> 01:02:36,310
 It seems inefficient to allocate large blocks or have many small blocks.

466
01:02:36,310 --> 01:02:43,910
 Yes, there is a big trade off here between having small blocks and large blocks.

467
01:02:43,910 --> 01:02:49,190
 You have what is called internal fragmentation or external fragmentation.

468
01:02:49,190 --> 01:02:53,750
 For instance, with large blocks, if you don't use an entire block, you allocate it, then

469
01:02:53,750 --> 01:02:59,910
 you waste memory and something like that.

470
01:02:59,910 --> 01:03:04,390
 And so, but yeah, so you need to be smart about it.

471
01:03:04,390 --> 01:03:10,870
 Today's operating systems allocate the memory in what is small blocks or pages which are

472
01:03:10,870 --> 01:03:16,310
 a few kilobytes, four kilobytes, 16 kilobytes or 32 kilobytes.

473
01:03:16,310 --> 01:03:20,390
 And then you have many, many of these small blocks.

474
01:03:20,390 --> 01:03:23,470
 Then you need to manage them efficiently.

475
01:03:23,470 --> 01:03:28,270
 And we are going to learn how this is done.

476
01:03:28,270 --> 01:03:32,510
 Ideally would application use yield when they are performing?

477
01:03:32,510 --> 01:03:33,510
 Absolutely.

478
01:03:33,510 --> 01:03:34,510
 That's a great point.

479
01:03:34,510 --> 01:03:35,510
 Sorry.

480
01:03:35,510 --> 01:03:43,310
 To read the full question, ideally would application use yield when they are performing IO operations?

481
01:03:43,310 --> 01:03:45,510
 Yes, that's exactly the case.

482
01:03:45,510 --> 01:03:51,350
 When you are going to send some data, then you can do yield because you can wait for

483
01:03:51,350 --> 01:04:01,790
 hours, excuse me, or when you are going to execute the yield or you can, when the interaction

484
01:04:01,790 --> 01:04:08,470
 on the application is interactive, like an editor, when I click on the keyboard, then

485
01:04:08,470 --> 01:04:12,230
 you see the characters appearing on the screen.

486
01:04:12,230 --> 01:04:21,110
 In that case, the editor will do yield after each time after it displays a character.

487
01:04:21,110 --> 01:04:29,670
 And it's going to wait for the next character to be typed in to arrive to get from the keyboard.

488
01:04:29,670 --> 01:04:41,830
 What does threads can share instruction mean on the previous slide?

489
01:04:41,830 --> 01:04:51,390
 So this means that, again, the threads are in the same address space.

490
01:04:51,390 --> 01:04:58,550
 And for instance, and even between processes, you can share that.

491
01:04:58,550 --> 01:05:05,230
 But if you have the same user, same libraries, and multiple thread user, same libraries,

492
01:05:05,230 --> 01:05:09,430
 you are going to have only one copy of the library, which is going to be shared by the

493
01:05:09,430 --> 01:05:12,350
 threads.

494
01:05:12,350 --> 01:05:16,190
 You are not going to have multiple copies.

495
01:05:16,190 --> 01:05:22,990
 Okay, so here is another picture showing the boundary, protection boundary and how the

496
01:05:22,990 --> 01:05:30,310
 raw resources, access to the raw resources is protected from the processes.

497
01:05:30,310 --> 01:05:38,470
 And like we discussed last time, and we already said a few times in this lecture, the OS operating

498
01:05:38,470 --> 01:05:40,510
 system isolate processes from each other.

499
01:05:40,510 --> 01:05:44,430
 So make sure they don't read and write data from each other.

500
01:05:44,430 --> 01:05:49,830
 The operating system also isolate itself from other processes.

501
01:05:49,830 --> 01:05:59,670
 And again, the challenge here, because all of those run on the same hardware.

502
01:05:59,670 --> 01:06:08,390
 This is again, some again, summary and repeating what was in the previous slide, maybe with

503
01:06:08,390 --> 01:06:11,870
 a little bit more details.

504
01:06:11,870 --> 01:06:18,790
 So the operating system has protected itself from the user programs, from the user processes.

505
01:06:18,790 --> 01:06:24,590
 And what does it mean?

506
01:06:24,590 --> 01:06:26,350
 And why is that needed?

507
01:06:26,350 --> 01:06:32,190
 This obviously for security, if the operating system is not protected, then it's easier

508
01:06:32,190 --> 01:06:38,190
 for an application to break into another application and read the confidential data or private

509
01:06:38,190 --> 01:06:39,190
 data.

510
01:06:39,190 --> 01:06:45,630
 I just mentioned about the privacy in the same example.

511
01:06:45,630 --> 01:06:48,630
 And the one of the main thing is reliability.

512
01:06:48,630 --> 01:06:59,030
 If the operating system fails, then the computer is unusable.

513
01:06:59,030 --> 01:07:07,270
 So the operating system, it better runs at all times.

514
01:07:07,270 --> 01:07:13,990
 And fairness, it's again, the operating system is the one which ensures that the processes,

515
01:07:13,990 --> 01:07:20,070
 different processes get a fair access to the hardware.

516
01:07:20,070 --> 01:07:25,870
 Program of course, like I mentioned, the operating system is to protect user programs from one

517
01:07:25,870 --> 01:07:27,630
 another.

518
01:07:27,630 --> 01:07:36,870
 And one of the primary mechanism of protections, it's translation.

519
01:07:36,870 --> 01:07:38,910
 And we'll see that next.

520
01:07:38,910 --> 01:07:45,790
 And the translation ensure that the process can only touch its own address space and cannot

521
01:07:45,790 --> 01:07:51,910
 touch the physical addresses of another process.

522
01:07:51,910 --> 01:07:55,870
 And there are a few of other mechanisms like privilege instruction, which can be only executed

523
01:07:55,870 --> 01:07:59,590
 by the operating system.

524
01:07:59,590 --> 01:08:05,830
 And there are some special registers only operating system has access to.

525
01:08:05,830 --> 01:08:10,390
 The third concept so far, we talk about threads, we talk about addresses.

526
01:08:10,390 --> 01:08:12,390
 We also talk quite a bit about processes.

527
01:08:12,390 --> 01:08:16,350
 This is again to make it explicit once more.

528
01:08:16,350 --> 01:08:25,630
 The process is basically another space plus one or more threads.

529
01:08:25,630 --> 01:08:33,830
 So processes allocate resources and then it has a thread, which basically is a unit of

530
01:08:33,830 --> 01:08:38,230
 execution.

531
01:08:38,230 --> 01:08:39,950
 And why do you have processes?

532
01:08:39,950 --> 01:08:42,590
 Because the processes protects from each other.

533
01:08:42,590 --> 01:08:44,870
 Threads do not protect from each other.

534
01:08:44,870 --> 01:08:46,590
 They share a same address space.

535
01:08:46,590 --> 01:08:51,550
 They share all the resources within the process.

536
01:08:51,550 --> 01:08:56,430
 However, threads are more efficient like we discussed.

537
01:08:56,430 --> 01:09:00,550
 The context switching between the thread in the same process is much quicker than between

538
01:09:00,550 --> 01:09:03,790
 threads in different processes.

539
01:09:03,790 --> 01:09:09,710
 Also communication between threads is in the same process much faster because you can use

540
01:09:09,710 --> 01:09:10,710
 shared memory.

541
01:09:10,710 --> 01:09:15,150
 You can use the address space, which is already shared between the threads to communicate

542
01:09:15,150 --> 01:09:18,670
 between the threads.

543
01:09:18,670 --> 01:09:24,310
 Between processes, you need to communicate through other means and you need to context

544
01:09:24,310 --> 01:09:29,790
 switch between the processes, which is far more expensive.

545
01:09:29,790 --> 01:09:34,670
 And typically an application consists of one or more processes, a process consists of one

546
01:09:34,670 --> 01:09:40,710
 or more threads.

547
01:09:40,710 --> 01:09:48,710
 And here you can see in this figure, on the left hand side, you see one process with a

548
01:09:48,710 --> 01:09:52,470
 single thread.

549
01:09:52,470 --> 01:09:54,150
 And you can see what belongs.

550
01:09:54,150 --> 01:10:04,750
 You have the process, you have the memory, address space, you have the code, data, file,

551
01:10:04,750 --> 01:10:09,710
 descriptors, register, stack.

552
01:10:09,710 --> 01:10:13,090
 So this belongs to our process.

553
01:10:13,090 --> 01:10:17,350
 And now on the right hand side, you have different thread in the same process.

554
01:10:17,350 --> 01:10:22,990
 And here you can see, notice at the top, the code and the data and the file descriptors,

555
01:10:22,990 --> 01:10:30,110
 all these resources are shared across all the threads in the same process.

556
01:10:30,110 --> 01:10:34,490
 What is not shared is the execution state of each thread.

557
01:10:34,490 --> 01:10:39,070
 So each thread comes with some registers, comes with some stack.

558
01:10:39,070 --> 01:10:40,070
 Right?

559
01:10:40,070 --> 01:10:46,390
 Registers includes the program counter, the stack pointer and things like that.

560
01:10:46,390 --> 01:10:55,910
 And the address encapsulate protection, right, it's a passive part of the process.

561
01:10:55,910 --> 01:11:07,510
 The thread is an active part, concurrency, encapsulate concurrency.

562
01:11:07,510 --> 01:11:16,990
 Why multiple threads for address space?

563
01:11:16,990 --> 01:11:24,310
 Yeah, too bad we cannot, it's hard to have this question answered if you have in the

564
01:11:24,310 --> 01:11:29,730
 class on this webinar.

565
01:11:29,730 --> 01:11:43,110
 But you want to have more because you want to build higher performance applications.

566
01:11:43,110 --> 01:11:49,550
 Like for instance, if you have an application which is doing, you have waiting from the

567
01:11:49,550 --> 01:11:55,070
 keyboard and they're doing some processing like rendering graphics and things like that,

568
01:11:55,070 --> 01:12:07,170
 and as a result of what the users, it's user's input, then you are going to have two threads

569
01:12:07,170 --> 01:12:13,810
 and you want this to communicate between others to send the user input to the thread which

570
01:12:13,810 --> 01:12:15,350
 is doing rendering.

571
01:12:15,350 --> 01:12:17,890
 And you want these two threads to be in the same process.

572
01:12:17,890 --> 01:12:22,210
 If they are not in the same processes, then you're going to be in a different process.

573
01:12:22,210 --> 01:12:26,430
 You need to incur context switching and things like that, which is going to be much less

574
01:12:26,430 --> 01:12:29,050
 efficient.

575
01:12:29,050 --> 01:12:31,050
 That's one example.

576
01:12:31,050 --> 01:12:36,090
 Okay, some examples, some questions now.

577
01:12:36,090 --> 01:12:40,030
 How can an application have multiple processes?

578
01:12:40,030 --> 01:12:44,910
 Is it if it needs multiple instances of a CPU or something?

579
01:12:44,910 --> 01:12:46,830
 What is the practical reasoning for this?

580
01:12:46,830 --> 01:12:52,350
 I thought it was one to one.

581
01:12:52,350 --> 01:12:58,030
 There are many reasons an application can have multiple processes.

582
01:12:58,030 --> 01:13:03,010
 And let me give you an extreme example and then you can imagine that will happen also

583
01:13:03,010 --> 01:13:05,050
 on a single machine.

584
01:13:05,050 --> 01:13:10,210
 An application like Facebook has obviously multiple processes because it runs on different

585
01:13:10,210 --> 01:13:11,210
 machines.

586
01:13:11,210 --> 01:13:15,530
 You have one part which is running on your machine, it's a front end, and then a part

587
01:13:15,530 --> 01:13:19,630
 which is running on the backend.

588
01:13:19,630 --> 01:13:25,130
 So you can imagine many of these applications like that could be client and server.

589
01:13:25,130 --> 01:13:30,030
 Some part of the application is handling, say, an access to the database and some part

590
01:13:30,030 --> 01:13:38,630
 of the application is handling the front end.

591
01:13:38,630 --> 01:13:43,110
 And then you can have a multi-user application and then you want to isolate the user from

592
01:13:43,110 --> 01:13:44,790
 each other in the same application.

593
01:13:44,790 --> 01:13:49,870
 So for each user you are going to provide a different process.

594
01:13:49,870 --> 01:13:55,510
 Or you want to have a stronger isolation, like for instance in your browser.

595
01:13:55,510 --> 01:13:58,390
 In your browser you have different tabs.

596
01:13:58,390 --> 01:14:10,030
 And if every tab you run it in the same process, then you have no protection and therefore

597
01:14:10,030 --> 01:14:16,390
 a misbehaving webpage can crash your browser.

598
01:14:16,390 --> 01:14:20,070
 If you have a stable process then you have strong isolation between processes.

599
01:14:20,070 --> 01:14:22,110
 So these are quite a few examples.

600
01:14:22,110 --> 01:14:30,230
 Now we are not going into details but there are more things between processes and threads

601
01:14:30,230 --> 01:14:35,710
 that are actually other ways people try to maintain the efficiency, to preserve the efficiency

602
01:14:35,710 --> 01:14:42,030
 of the thread, but add some protection which you have from processes.

603
01:14:42,030 --> 01:14:45,490
 We are not going to discuss about this though.

604
01:14:45,490 --> 01:14:49,050
 But hopefully I answered that question.

605
01:14:49,050 --> 01:14:54,190
 So that attack doesn't depend on waiting, can take over while the other is waiting,

606
01:14:54,190 --> 01:15:00,790
 even if the CPU is multiplex.

607
01:15:00,790 --> 01:15:17,830
 I'm afraid I don't, this is a statement I guess.

608
01:15:17,830 --> 01:15:19,830
 But what this statement said is correct.

609
01:15:19,830 --> 01:15:22,390
 The task which doesn't depend on waiting can take over.

610
01:15:22,390 --> 01:15:27,910
 The task which depends on waiting is going to be suspended to wait for some part.

611
01:15:27,910 --> 01:15:35,630
 So a task which, a process which waits for an event to happen, like getting an input

612
01:15:35,630 --> 01:15:42,590
 event from getting some data from the network, is suspended and waiting for that event to

613
01:15:42,590 --> 01:15:46,230
 happen and during that time another process can run.

614
01:15:46,230 --> 01:15:56,050
 The operating system can take care of that.

615
01:15:56,050 --> 01:16:00,650
 And finally the fourth operating system concept is dual mode operation.

616
01:16:00,650 --> 01:16:11,670
 So dual mode operation is fundamentally concerned about how you are going to share the hardware,

617
01:16:11,670 --> 01:16:22,070
 the machine between processes, the user processes and the operating system.

618
01:16:22,070 --> 01:16:24,550
 And typically this happens, you have two modes for that.

619
01:16:24,550 --> 01:16:31,310
 You have a user mode, which is used when you run a user process and the kernel mode, which

620
01:16:31,310 --> 01:16:33,870
 is used when the operating system runs.

621
01:16:33,870 --> 01:16:41,210
 And the reason for that is the operating system actually has access to a lot more resources

622
01:16:41,210 --> 01:16:50,090
 and even to processes, resources during when it is running.

623
01:16:50,090 --> 01:16:56,370
 And the way to differentiate between these two modes is you have a bit and it's a user

624
01:16:56,370 --> 01:16:58,390
 system mode bit.

625
01:16:58,390 --> 01:17:07,950
 So when you set to zero, for instance, it's a user mode and you set one is kernel mode.

626
01:17:07,950 --> 01:17:16,650
 So how the transition happened from a user process to a kernel happens from the user

627
01:17:16,650 --> 01:17:19,730
 to kernel, you set the system out.

628
01:17:19,730 --> 01:17:32,790
 So now, and then save the user program counters and all the state of that particular thread

629
01:17:32,790 --> 01:17:35,470
 and execution state.

630
01:17:35,470 --> 01:17:41,390
 And then from the kernel to the user transition, you clear the system and restore the appropriate

631
01:17:41,390 --> 01:17:48,770
 user program counter.

632
01:17:48,770 --> 01:17:51,510
 And you can return from the interrupt.

633
01:17:51,510 --> 01:17:57,450
 And here how the user mode and the kernel mode interact with each other.

634
01:17:57,450 --> 01:18:01,290
 So on one hand, from the kernel mode, you have EXACT.

635
01:18:01,290 --> 01:18:05,310
 And this is how you run a process.

636
01:18:05,310 --> 01:18:11,990
 The kernel and the operating system is launching a new process.

637
01:18:11,990 --> 01:18:15,490
 Then when the process exits, you return to the kernel.

638
01:18:15,490 --> 01:18:19,310
 The kernel is taking care of freeing all the resources allocated to that process.

639
01:18:19,310 --> 01:18:23,990
 So these resources can be used by other processes.

640
01:18:23,990 --> 01:18:26,510
 Then it's a system call.

641
01:18:26,510 --> 01:18:33,830
 And this is when the user process requires some functionality, some services, invokes

642
01:18:33,830 --> 01:18:37,750
 some services from the operating system.

643
01:18:37,750 --> 01:18:44,870
 Example of some services like accessing a file, sending some data, reading information

644
01:18:44,870 --> 01:18:48,290
 input data from the keyboard.

645
01:18:48,290 --> 01:18:49,290
 And this is returned.

646
01:18:49,290 --> 01:18:53,990
 This is after the operating system satisfies this request.

647
01:18:53,990 --> 01:18:59,430
 Then it's returning control back to the user.

648
01:18:59,430 --> 01:19:03,070
 And then there are user interrupts.

649
01:19:03,070 --> 01:19:06,370
 And the user interrupts.

650
01:19:06,370 --> 01:19:10,030
 One example is basically you can have a SQL.

651
01:19:10,030 --> 01:19:14,950
 You can actually kill a process.

652
01:19:14,950 --> 01:19:20,830
 So that's one example of a user interrupt.

653
01:19:20,830 --> 01:19:23,810
 And there are also interrupts which come from the hardware.

654
01:19:23,810 --> 01:19:34,030
 Like when a packet arrives, where when you click on a keyboard and then you have an interrupt,

655
01:19:34,030 --> 01:19:39,030
 so the operating system needs to read the symbols.

656
01:19:39,030 --> 01:19:41,030
 And then you can return from the interrupt.

657
01:19:41,030 --> 01:19:42,030
 It's a user-level interrupt.

658
01:19:42,030 --> 01:19:44,030
 You return from the interrupt.

659
01:19:44,030 --> 01:19:49,870
 You return the control eventually to the user.

660
01:19:49,870 --> 01:19:54,390
 And finally, there are exceptions.

661
01:19:54,390 --> 01:20:05,910
 And exceptions are when the user somehow the program is doing something which is not allowed.

662
01:20:05,910 --> 01:20:12,790
 Like for instance, you can have division by zero.

663
01:20:12,790 --> 01:20:13,790
 Okay.

664
01:20:13,790 --> 01:20:13,790
 Thank you.

665
01:20:13,790 --> 01:20:14,790
 [ Applause ]

666
01:20:14,790 --> 01:20:15,790
 [ Applause ]

667
01:20:15,790 --> 01:20:16,790
 [ Applause ]

668
01:20:16,790 --> 01:20:17,790
 [ Applause ]

669
01:20:17,790 --> 01:20:18,790
 [ Applause ]

670
01:20:18,790 --> 01:20:19,790
 [ Applause ]

671
01:20:19,790 --> 01:20:20,790
 [ Applause ]

672
01:20:20,790 --> 01:20:21,790
 [ Applause ]

673
01:20:21,790 --> 01:20:22,790
 [ Applause ]

674
01:20:22,790 --> 01:20:23,790
 [ Applause ]

675
01:20:23,790 --> 01:20:24,790
 [ Applause ]

676
01:20:24,790 --> 01:20:25,790
 [ Applause ]

677
01:20:25,790 --> 01:20:26,790
 [ Applause ]

678
01:20:26,790 --> 01:20:27,790
 [ Applause ]

679
01:20:27,790 --> 01:20:27,790
 [ Applause ]

680
01:20:27,790 --> 01:20:28,790
 [ Applause ]

681
01:20:28,790 --> 01:20:29,790
 [ Applause ]

682
01:20:29,790 --> 01:20:30,790
 [ Applause ]

683
01:20:30,790 --> 01:20:30,790
 [ Applause ]

684
01:20:30,790 --> 01:20:31,790
 [ Applause ]

685
01:20:31,790 --> 01:20:32,790
 [ Applause ]

686
01:20:32,790 --> 01:20:33,790
 [ Applause ]

687
01:20:33,790 --> 01:20:34,790
 [ Applause ]

688
01:20:34,790 --> 01:20:35,790
 [ Applause ]

689
01:20:35,790 --> 01:20:37,790
 Thank you.

690
01:20:37,790 --> 01:20:39,790
 >>

691
01:20:39,790 --> 01:20:41,790
 >>

692
01:20:41,790 --> 01:20:43,790
 >>

693
01:20:43,790 --> 01:20:45,790
 >>

694
01:20:45,790 --> 01:20:47,790
 >>

695
01:20:47,790 --> 01:20:49,790
 >>

696
01:20:49,790 --> 01:20:51,790
 >>

697
01:20:51,790 --> 01:20:53,790
 >>

698
01:20:53,790 --> 01:21:13,790
 [ Silence ]

